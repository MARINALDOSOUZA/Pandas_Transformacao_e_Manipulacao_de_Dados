import pandas as pd
import requests
import re
import logging
import os
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.ticker as mticker
import matplotlib.dates as mdates
import locale

# --- LOGGING BÁSICO ---
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

def texto_extenso_para_numero(texto):
    """
    Converte uma string contendo um número por extenso (em português) para seu valor numérico.
    Ex: 'cinco' -> 5, 'vinte e três' -> 23.
    Retorna None se a conversão não for possível.
    """
    unidades = {
        'zero': 0, 'um': 1, 'uma': 1, 'dois': 2, 'duas': 2, 'três': 3, 'quatro': 4,
        'cinco': 5, 'seis': 6, 'sete': 7, 'oito': 8, 'nove': 9
    }
    dezenas = {
        'dez': 10, 'onze': 11, 'doze': 12, 'treze': 13, 'quatorze': 14, 'quinze': 15,
        'dezesseis': 16, 'dezessete': 17, 'dezoito': 18, 'dezenove': 19,
        'vinte': 20, 'trinta': 30, 'quarenta': 40, 'cinquenta': 50, 'sessenta': 60,
        'setenta': 70, 'oitenta': 80, 'noventa': 90
    }
    centenas = {
        'cem': 100, 'cento': 100, 'duzentos': 200, 'trezentos': 300, 'quatrocentos': 400,
        'quinhentos': 500, 'seiscentos': 600, 'setecentos': 700,
        'oitocentos': 800, 'novecentos': 900
    }
    milhares = {
        'mil': 1000
    }

    palavras = texto.lower().split()
    total = 0
    atual = 0

    for palavra in palavras:
        if palavra in unidades:
            atual += unidades[palavra]
        elif palavra in dezenas:
            atual += dezenas[palavra]
        elif palavra in centenas:
            atual += centenas[palavra]
        elif palavra in milhares:
            if atual == 0:
                atual = 1
            total += atual * milhares[palavra]
            atual = 0
        elif palavra == 'e':
            continue
        else:
            return None

    return total + atual if total + atual > 0 else None

def extrair_dataframe(json_obj):
    """
    Extrai dados de um objeto JSON (lista ou dicionário) e os normaliza em um DataFrame pandas.
    Lida com colunas que podem conter listas aninhadas, explodindo-as em novas linhas.
    """
    if isinstance(json_obj, list):
        df = pd.json_normalize(json_obj)
    elif isinstance(json_obj, dict):
        for k, v in json_obj.items():
            if isinstance(v, list) and len(v) > 0 and isinstance(v[0], dict):
                df = pd.json_normalize(v)
                break
        else:
            df = pd.json_normalize(json_obj)
    else:
        raise ValueError("Formato JSON inválido: esperado lista ou dicionário.")

    colunas_para_explodir = [col for col in df.columns if df[col].apply(lambda x: isinstance(x, list)).any()]
    for col in colunas_para_explodir:
        df = df.explode(col).reset_index(drop=True)

    return df

def tratar_dados_especificos(df):
    """
    Aplica tratamentos específicos aos dados do DataFrame, como conversão de datas
    e valores monetários, e padronização de strings.
    """
    df_tratado = df.copy()

    for col in df_tratado.columns:
        dados = df_tratado[col]

        if re.search(r'data|date|dt', col, re.IGNORECASE):
            df_tratado[col] = pd.to_datetime(dados, errors='coerce', dayfirst=True)

        elif col == 'valor_aluguel':
            valores = []

            for val in dados.astype(str):
                original = val.lower().strip()
                val_limpo = re.sub(r'[^\d,\.]', '', original)

                try:
                    valores.append(locale.atof(val_limpo))
                    continue
                except (ValueError, AttributeError):
                    pass

                val_texto = re.sub(r'[^a-záéíóúãõç\s]', '', original)
                numero = texto_extenso_para_numero(val_texto)
                valores.append(float(numero) if numero is not None else None)

            df_tratado[col] = pd.Series(valores)

        elif dados.dtype == 'object':
            df_tratado[col] = dados.str.strip().str.title()

    return df_tratado

def otimizar_tipos_numericos(df):
    """
    Otimiza os tipos de dados de colunas numéricas (int e float)
    para usar a menor representação possível que ainda seja segura.
    Reduz o consumo de memória e o tamanho do arquivo.
    """
    df_otimizado = df.copy()

    for col in df_otimizado.select_dtypes(include=['float', 'int']).columns:
        col_data = df_otimizado[col]

        # Tenta primeiro fazer downcast para inteiro se todos os valores (não NaN) forem inteiros
        # ou se a coluna já for de tipo inteiro
        if pd.api.types.is_integer_dtype(col_data) or (col_data.dropna() % 1 == 0).all():
            try:
                df_otimizado[col] = pd.to_numeric(col_data, downcast='integer')
            except Exception as e:
                logger.debug(f"Não foi possível fazer downcast para inteiro na coluna {col}: {e}")
                # Fallback para float se o downcast para int falhar por algum motivo
                df_otimizado[col] = pd.to_numeric(col_data, downcast='float')
        else:
            # Se não for inteiro (ou tiver decimais), tenta downcast para float32
            df_otimizado[col] = pd.to_numeric(col_data, downcast='float')
            
    return df_otimizado

def relatorio_validacao(df_original, df_tratado):
    """
    Gera um relatório de validação mostrando a quantidade de linhas e colunas
    no DataFrame original e após o tratamento.
    """
    total_rows = len(df_original)
    total_cols_original = df_original.shape[1]

    aproveitadas_rows = len(df_tratado.dropna(how='all'))
    descartadas_rows = total_rows - aproveitadas_rows

    aproveitadas_cols = df_tratado.shape[1]
    descartadas_cols = total_cols_original - aproveitadas_cols

    print("\n--- RELATÓRIO DE VALIDAÇÃO ---")
    print(f"Linhas totais no JSON original: {total_rows}")
    print(f"Colunas totais no JSON original: {total_cols_original}")
    print(f"Linhas aproveitadas: {aproveitadas_rows} ({(aproveitadas_rows / total_rows) * 100:.2f}%)")
    print(f"Colunas aproveitadas: {aproveitadas_cols}")
    print(f"Linhas descartadas: {descartadas_rows} ({(descartadas_rows / total_rows) * 100:.2f}%)")
    print(f"Colunas descartadas: {descartadas_cols}")

    if descartadas_cols == 0 and aproveitadas_cols == total_cols_original:
        print("(Nota: No processo de tratamento atual, colunas não são removidas, apenas seus valores são modificados.)")

def criar_backup(arquivo_csv):
    """
    Cria um backup do arquivo CSV existente, renomeando-o com um timestamp.
    """
    pasta_backup = 'backups'
    if not os.path.exists(pasta_backup):
        os.makedirs(pasta_backup)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    nome_backup = f"{os.path.splitext(arquivo_csv)[0]}_backup_{timestamp}.csv"
    caminho_backup = os.path.join(pasta_backup, nome_backup)

    if os.path.exists(arquivo_csv):
        os.rename(arquivo_csv, caminho_backup)
        logger.info(f"Backup criado: {caminho_backup}")
    else:
        logger.warning(f"Arquivo '{arquivo_csv}' não encontrado para backup.")

def formatar_valor_brl(valor):
    """
    Formata um valor numérico para o formato de moeda brasileira (R$).
    """
    if pd.isna(valor):
        return "R$ NaN"
    else:
        # Usa locale.format_string para garantir a formatação correta
        # '%.2f' para duas casas decimais, True para agrupamento de milhares
        return locale.currency(valor, grouping=True, symbol=True) 

def encontrar_coluna_por_regex(df, padrao):
    """
    Encontra o nome de uma coluna em um DataFrame usando uma expressão regular.
    Retorna o nome da coluna ou None se não encontrar.
    """
    for col in df.columns:
        if re.search(padrao, col, re.IGNORECASE):
            return col
    return None

def mostrar_visao_geral(df):
    """
    Exibe uma visão geral das primeiras ou de um intervalo de linhas do DataFrame,
    com a adição de uma coluna fictícia de 'Status_Pagamento_Visual' para clareza.
    """
    print("\n### VISÃO GERAL DO DATAFRAME ###")
    total_linhas = len(df)
    entrada = input("Digite o número de linhas para mostrar, intervalo (ex: 10:20) ou ENTER para 50 linhas: ").strip()

    df_display = df.copy() 
    
    col_valor_aluguel = encontrar_coluna_por_regex(df_display, r'valor_aluguel')
    if col_valor_aluguel and pd.api.types.is_numeric_dtype(df_display[col_valor_aluguel]):
        df_display[col_valor_aluguel] = df_display[col_valor_aluguel].apply(formatar_valor_brl)

    col_pagamento = encontrar_coluna_por_regex(df_display, r'datas_de_pagamento')
    col_vencimento = encontrar_coluna_por_regex(df_display, r'datas_combinadas_pagamento')

    if col_pagamento and col_vencimento:
        pagamentos = pd.to_datetime(df_display[col_pagamento], errors='coerce')
        vencimentos = pd.to_datetime(df_display[col_vencimento], errors='coerce')

        df_display['Status_Pagamento_Visual'] = 'N/A'
        valid_dates_mask = pagamentos.notna() & vencimentos.notna()
        df_display.loc[valid_dates_mask, 'Status_Pagamento_Visual'] = (
            (pagamentos[valid_dates_mask] <= vencimentos[valid_dates_mask])
            .map({True: 'Em dia', False: 'Atrasado'})
        )
    else:
        logger.warning("Colunas de data de pagamento ou vencimento não encontradas para criar o status visual.")

    try:
        start, end = 0, 0
        if entrada == '':
            start, end = 0, 50
        elif ':' in entrada:
            parts = entrada.split(':')
            start = int(parts[0]) if parts[0] else 0
            end = int(parts[1]) if len(parts) > 1 and parts[1] else total_linhas
        else:
            start, end = 0, int(entrada)
        
        if start < 0: start = 0
        if end > total_linhas: end = total_linhas
        if start >= end:
            print("Intervalo inválido ou vazio. Mostrando as primeiras 50 linhas.")
            start, end = 0, min(50, total_linhas)

        print(df_display.iloc[start:end].to_string(index=False))
    except ValueError:
        print("Entrada inválida. Por favor, digite um número, um intervalo (ex: 10:20) ou ENTER.")
    except Exception as e:
        print(f"Ocorreu um erro: {e}")

def mostrar_visao_financeira(df):
    """
    Exibe um resumo financeiro dos pagamentos, dividindo-os em 'Em Dia' e 'Atrasados',
    com somatório e média dos valores de aluguéis.
    """
    print("\n### VISÃO FINANCEIRA ###")

    df_copy = df.copy()

    col_pagamento = encontrar_coluna_por_regex(df_copy, r'datas_de_pagamento')
    col_vencimento = encontrar_coluna_por_regex(df_copy, r'datas_combinadas_pagamento')
    col_valor_aluguel = encontrar_coluna_por_regex(df_copy, r'valor_aluguel')

    if not col_pagamento or not col_vencimento or not col_valor_aluguel:
        print("Colunas necessárias (data de pagamento, vencimento e/ou valor do aluguel) não foram encontradas.")
        print(f"Colunas disponíveis: {list(df_copy.columns)}")
        return
    
    df_financeiro = df_copy[[col_pagamento, col_vencimento, col_valor_aluguel]].copy()
    df_financeiro.columns = ['data_pagamento', 'data_vencimento', 'valor_aluguel']

    df_financeiro['data_pagamento'] = pd.to_datetime(df_financeiro['data_pagamento'], errors='coerce')
    df_financeiro['data_vencimento'] = pd.to_datetime(df_financeiro['data_vencimento'], errors='coerce')
    df_financeiro['valor_aluguel'] = pd.to_numeric(df_financeiro['valor_aluguel'], errors='coerce')

    df_financeiro.dropna(subset=['data_pagamento', 'data_vencimento', 'valor_aluguel'], inplace=True)

    if df_financeiro.empty:
        print("Não há dados válidos para a visão financeira após o tratamento das datas e valores.")
        return

    pag_em_dia = df_financeiro[df_financeiro['data_pagamento'] <= df_financeiro['data_vencimento']]
    pag_atraso = df_financeiro[df_financeiro['data_pagamento'] > df_financeiro['data_vencimento']]
    
    total_apts_validos = len(df_financeiro)
    total_alugueis_validos = df_financeiro['valor_aluguel'].sum()

    print("\n--- RESUMO DOS PAGAMENTOS ---")
    
    qtd_em_dia = len(pag_em_dia)
    soma_aluguel_em_dia = pag_em_dia['valor_aluguel'].sum()
    media_aluguel_em_dia = pag_em_dia['valor_aluguel'].mean() if qtd_em_dia > 0 else 0
    
    porc_apts_em_dia = (qtd_em_dia / total_apts_validos) * 100 if total_apts_validos > 0 else 0
    porc_valor_em_dia = (soma_aluguel_em_dia / total_alugueis_validos) * 100 if total_alugueis_validos > 0 else 0

    print(f"\n** Pagamentos Em Dia ou Adiantados **")
    print(f"Total de Apartamentos: {qtd_em_dia} ({porc_apts_em_dia:.2f}%)")
    print(f"Soma dos Valores de Aluguéis: {formatar_valor_brl(soma_aluguel_em_dia)}")
    print(f"Média dos Valores de Aluguéis: {formatar_valor_brl(media_aluguel_em_dia)}")
    print(f"Porcentagem do Total de Aluguéis Válidos: {porc_valor_em_dia:.2f}%")

    qtd_atraso = len(pag_atraso)
    soma_aluguel_atraso = pag_atraso['valor_aluguel'].sum()
    media_aluguel_atraso = pag_atraso['valor_aluguel'].mean() if qtd_atraso > 0 else 0

    porc_apts_atraso = (qtd_atraso / total_apts_validos) * 100 if total_apts_validos > 0 else 0
    porc_valor_atraso = (soma_aluguel_atraso / total_alugueis_validos) * 100 if total_alugueis_validos > 0 else 0

    print(f"\n** Pagamentos Atrasados **")
    print(f"Total de Apartamentos: {qtd_atraso} ({porc_apts_atraso:.2f}%)")
    print(f"Soma dos Valores de Aluguéis: {formatar_valor_brl(soma_aluguel_atraso)}")
    print(f"Média dos Valores de Aluguéis: {formatar_valor_brl(media_aluguel_atraso)}")
    print(f"Porcentagem do Total de Aluguéis Válidos: {porc_valor_atraso:.2f}%")

    print(f"\nTotal Geral de Apartamentos Válidos para Análise: {total_apts_validos}")
    print(f"Soma Total Geral de Aluguéis Válidos para Análise: {formatar_valor_brl(total_alugueis_validos)}")


def mostrar_estatisticas(df):
    """
    Gera um gráfico de linha mostrando a evolução diária dos pagamentos
    divididos por status (em dia ou atrasado), com destaques para picos.
    """
    print("\n### ESTATÍSTICAS DE PAGAMENTOS ###")

    col_pagamento = encontrar_coluna_por_regex(df, r'datas_de_pagamento')
    col_vencimento = encontrar_coluna_por_regex(df, r'datas_combinadas_pagamento')

    if not col_pagamento or not col_vencimento:
        print("Não foi possível encontrar colunas para gerar estatísticas.")
        return

    df_estatisticas = df.copy()
    df_estatisticas['data_pagamento'] = pd.to_datetime(df_estatisticas[col_pagamento], errors='coerce')
    df_estatisticas['data_vencimento'] = pd.to_datetime(df_estatisticas[col_vencimento], errors='coerce')

    df_estatisticas.dropna(subset=['data_pagamento', 'data_vencimento'], inplace=True)

    if df_estatisticas.empty:
        print("Não há dados válidos para gerar estatísticas de pagamentos após o tratamento das datas.")
        return

    df_estatisticas['status_pagamento'] = df_estatisticas['data_pagamento'] <= df_estatisticas['data_vencimento']

    pagamentos_diarios = df_estatisticas.groupby(['data_pagamento', 'status_pagamento']).size().unstack(fill_value=0)
    pagamentos_diarios = pagamentos_diarios.sort_index()

    sns.set(style="whitegrid")
    fig, ax = plt.subplots(figsize=(14, 6))

    if True in pagamentos_diarios.columns and not pagamentos_diarios[True].empty:
        pico_data = pagamentos_diarios[True].idxmax()
        pico_valor = pagamentos_diarios[True].max()
        
        sns.lineplot(x=pagamentos_diarios.index, y=pagamentos_diarios[True], label='Pagamento Em Dia', color='blue', marker='o', ax=ax)
        ax.scatter([pico_data], [pico_valor], color='blue', s=150, edgecolors='black', label=f'Pico Em Dia ({pico_data.strftime("%Y-%m-%d")}: {pico_valor})', zorder=5)

    if False in pagamentos_diarios.columns and not pagamentos_diarios[False].empty:
        pico_data_atraso = pagamentos_diarios[False].idxmax()
        pico_valor_atraso = pagamentos_diarios[False].max()
        
        sns.lineplot(x=pagamentos_diarios.index, y=pagamentos_diarios[False], label='Pagamento Atrasado', color='red', marker='o', ax=ax)
        ax.scatter([pico_data_atraso], [pico_valor_atraso], color='red', s=150, edgecolors='black', label=f'Pico Atrasado ({pico_data_atraso.strftime("%Y-%m-%d")}: {pico_valor_atraso})', zorder=5)

    ax.set_title("Evolução de Pagamentos por Status")
    ax.set_xlabel("Data do Pagamento")
    ax.set_ylabel("Quantidade de Apartamentos")
    ax.legend()
    ax.grid(True, which='both', linestyle='--', linewidth=0.5)

    if not pagamentos_diarios.empty:
        min_date = pagamentos_diarios.index.min()
        max_date = pagamentos_diarios.index.max()
        delta_days = (max_date - min_date).days

        if delta_days < 90:
            ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
        elif delta_days < 365:
            ax.xaxis.set_major_locator(mdates.MonthLocator())
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
        else:
            ax.xaxis.set_major_locator(mdates.YearLocator())
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
            ax.xaxis.set_minor_locator(mdates.MonthLocator(interval=3))

        ax.tick_params(axis='x', labelrotation=45) 
        plt.setp(ax.get_xticklabels(), ha='right') 

    plt.tight_layout()
    plt.show()

def processar_json_e_salvar(url, arquivo_csv):
    """
    Função principal para baixar, extrair, tratar, OTIMIZAR e salvar os dados JSON em CSV.
    Retorna o DataFrame tratado e otimizado.
    """
    df_tratado_local = pd.DataFrame()
    try:
        logger.info("Baixando dados JSON...")
        response = requests.get(url)
        response.raise_for_status()
        dados_json = response.json()

        logger.info("Extraindo e tratando dados...")
        df_raw = extrair_dataframe(dados_json)
        df_tratado_local = tratar_dados_especificos(df_raw)
        
        # --- APLICAÇÃO DA OTIMIZAÇÃO DE TIPOS NUMÉRICOS (NOVA ETAPA) ---
        logger.info("Otimizando tipos de dados numéricos para reduzir consumo de memória...")
        df_tratado_local = otimizar_tipos_numericos(df_tratado_local)
        # --- FIM DA APLICAÇÃO DA OTIMIZAÇÃO ---

        df_tratado_local.to_csv(arquivo_csv, index=False)

        logger.info(f"Arquivo CSV salvo como {arquivo_csv}")
        relatorio_validacao(df_raw, df_tratado_local)
    except requests.exceptions.RequestException as e:
        logger.error(f"Erro de conexão ou requisição ao baixar JSON: {e}")
        df_tratado_local = pd.DataFrame()
    except ValueError as e:
        logger.error(f"Erro ao processar JSON (formato inválido?): {e}")
        df_tratado_local = pd.DataFrame()
    except Exception as e:
        logger.error(f"Erro inesperado durante processamento do JSON: {e}")
        df_tratado_local = pd.DataFrame()
    return df_tratado_local

def main():
    """
    Função principal que gerencia o fluxo do programa, incluindo
    carregamento de dados, backup e o menu interativo.
    """
    # --- Configuração do Locale para Parsing Numérico ---
    # É crucial para que `locale.atof` e `locale.currency` interpretem corretamente números e moedas.
    try:
        # Tenta configurar para Linux/macOS
        locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')
        logger.info("Locale configurado para 'pt_BR.UTF-8'.")
    except locale.Error:
        try:
            # Fallback comum para Windows ou outros sistemas
            locale.setlocale(locale.LC_ALL, 'Portuguese_Brazil.1252')
            logger.info("Locale configurado para 'Portuguese_Brazil.1252'.")
        except locale.Error:
            logger.warning("Não foi possível configurar o locale para 'pt_BR'. O parsing numérico e a formatação de moeda podem ser menos robustos para o formato brasileiro.")
    # --- Fim da configuração do Locale ---

    url = 'https://cdn3.gnarususercontent.com.br/2928-transformacao-manipulacao-dados/dados_locacao_imoveis.json'
    arquivo_csv = 'df_locacao_imoveis.csv'

    df_tratado = pd.DataFrame()

    if not os.path.exists(arquivo_csv):
        logger.info("Arquivo CSV não encontrado. Criando novo arquivo a partir do JSON.")
        df_tratado = processar_json_e_salvar(url, arquivo_csv)
    else:
        resposta = input(f"O arquivo '{arquivo_csv}' já existe. Deseja atualizar? (s/n): ").strip().lower()
        if resposta != 's':
            logger.info(f"Carregando arquivo existente '{arquivo_csv}'...")
            try:
                # Ao carregar do CSV, já se espera que os tipos estejam otimizados se foram salvos assim.
                # As colunas de data ainda precisam de conversão explícita.
                df_tratado = pd.read_csv(arquivo_csv)
                for col in df_tratado.columns:
                    if re.search(r'data|date|dt', col, re.IGNORECASE):
                        df_tratado[col] = pd.to_datetime(df_tratado[col], errors='coerce', dayfirst=True)
            except Exception as e:
                logger.error(f"Erro ao carregar o arquivo CSV: {e}. Tentando baixar novamente.")
                df_tratado = processar_json_e_salvar(url, arquivo_csv)
        else:
            criar_backup(arquivo_csv)
            df_tratado = processar_json_e_salvar(url, arquivo_csv)

    if not df_tratado.empty:
        menu(df_tratado)
    else:
        logger.error("Não foi possível carregar ou processar os dados. Encerrando.")

def menu(df):
    """
    Exibe o menu principal para o usuário e direciona para as diferentes análises.
    """
    while True:
        print("\n=== MENU PRINCIPAL ===")
        print("1 - Visão Geral")
        print("2 - Visão Financeira")
        print("3 - Estatísticas")
        print("0 - Sair")
        opcao = input("Escolha uma opção: ").strip()

        if opcao == '1':
            mostrar_visao_geral(df)
        elif opcao == '2':
            mostrar_visao_financeira(df)
        elif opcao == '3':
            mostrar_estatisticas(df)
        elif opcao == '0':
            print("Encerrando programa.")
            break
        else:
            print("Opção inválida. Tente novamente.")

if __name__ == "__main__":
    main()
